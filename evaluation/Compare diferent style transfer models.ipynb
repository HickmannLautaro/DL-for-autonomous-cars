{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c08f6c-3251-4d1e-b3b8-ffaf8d498230",
   "metadata": {},
   "source": [
    "# Important clear all outputs before saving, otherwise its around 500 mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7180687d-5046-4a83-8b3b-254de0f26692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.gridspec import SubplotSpec\n",
    "from skimage import feature, measure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr\n",
    "from skimage.morphology import dilation, closing, white_tophat, disk\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos_sim\n",
    "\n",
    "from IPython.display import HTML\n",
    "plt.rcParams['animation.embed_limit'] = 2**128\n",
    "warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb7639-c493-4a90-a302-48ea74ecae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = 50\n",
    "frame_steps = 5\n",
    "eval_type = \"test\"\n",
    "dataset = f\"road_tree_new_{eval_type}\" # road_tree_new_test or road_tree_new_train\n",
    "real_style_0 = glob.glob(f'./styletransfer/cut/datasets/{dataset}/trainB/*_0.jpg*')\n",
    "real_style_1 = glob.glob(f'./styletransfer/cut/datasets/{dataset}/trainB/*_1.jpg*')\n",
    "real_style_0 = np.array([np.asarray(Image.open(fname)) for fname in real_style_0])\n",
    "real_style_1 = np.array([np.asarray(Image.open(fname)) for fname in real_style_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f6764-c9b6-42af-bb2c-d5cfd4c6ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load(f\"files_for_style_comparisson/continuous_trees_test.npz\")#np.load(f\"files_for_style_comparisson/new_trees_{eval_type}.npz\")#np.load(\"files_for_style_comparisson/createdat_2021-06-13 08:46:46.597627.npz\")\n",
    "names = loaded[\"names\"]\n",
    "steps = loaded[\"steps\"]\n",
    "experiments = loaded[\"frames\"]\n",
    "\n",
    "openAI_data = experiments[0]\n",
    "\n",
    "edges = loaded['edges']\n",
    "edges = np.squeeze(edges/255).astype(float)\n",
    "edge_names = loaded['edge_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204bb0b1-d216-4f9f-843c-f6673c6acbab",
   "metadata": {},
   "source": [
    "# FID score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8998cc-6ea4-4454-9b41-021f9d104acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pytorch_fid.fid_score import calculate_fid_given_paths\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1096507-f9d2-464c-9fe3-e438bc05f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FID_score(names,experiments,real_style_0,real_style_1, dim):\n",
    "    tmp_path = './tmp'\n",
    "    os.mkdir(tmp_path)\n",
    "    tgt_path0=tmp_path+'/target0'\n",
    "    os.mkdir(tgt_path0)\n",
    "    tgt_path1=tmp_path+'/target1'\n",
    "    os.mkdir(tgt_path1)\n",
    "    pred_path = tmp_path+'/prediction'\n",
    "    os.mkdir(pred_path)\n",
    "    nms = [n[10:] for n in names[1:]]\n",
    "    predictions =experiments[1:]\n",
    "\n",
    "    for i, image in enumerate(real_style_0):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(f\"{tgt_path0}/tgt_{i}.jpg\", image)\n",
    "\n",
    "    for i, image in enumerate(real_style_1):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(f\"{tgt_path1}/tgt_{i}.jpg\", image)\n",
    "\n",
    "    for j,exp in enumerate(predictions):\n",
    "        os.mkdir(f\"{pred_path}/{nms[j]}\")\n",
    "        for i, image in enumerate(exp):\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(f\"{pred_path}/{nms[j]}/pred_{i}.jpg\", image)\n",
    "\n",
    "    os.mkdir(f\"{pred_path}/org\")\n",
    "    for i, image in enumerate(experiments[0]):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(f\"{pred_path}/org/pred_{i}.jpg\", image)\n",
    "\n",
    "    dev = torch.device('cuda' if (torch.cuda.is_available()) else 'cpu')\n",
    "\n",
    "\n",
    "    fid_values = [calculate_fid_given_paths(paths=[tgt, pred], batch_size=50, device=dev, dims=dim) for (tgt, pred) in zip([tgt_path0, tgt_path1]*((len(nms)//2)+3),[tgt_path0, tgt_path1]+[f\"{pred_path}/{nm}\" for nm in nms]+[f\"{pred_path}/org\"]*2)]\n",
    "\n",
    "    shutil.rmtree(tmp_path)\n",
    "    labels = ['originals']+[n[14:-2] for n in nms[::2]]+[\"openAI\"]\n",
    "    x = np.arange(len(labels))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "    rects1 = ax.bar(x - width/2, fid_values[::2], width, label='Style 0', color='yellowgreen')\n",
    "    rects2 = ax.bar(x + width/2, fid_values[1::2], width, label='Style 1', color='saddlebrown')\n",
    "    ax.set_ylim(top= np.max(fid_values[:-2])*1.1)\n",
    "\n",
    "\n",
    "    if dim == 64: \n",
    "        conf = \"first max pooling features\"\n",
    "    if dim == 192: \n",
    "        conf = \"second max pooling features\"\n",
    "    if dim == 768: \n",
    "        conf = \"pre-aux classifier features\"\n",
    "    if dim == 2048:\n",
    "        conf = \"final average pooling features\"\n",
    "\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('FID Scores')\n",
    "    ax.set_title(f\"FID Score per Model and style comparing predictions and target datasets(lower is better)\\nfeature dim {dim}\\n {conf}; OpenAI vals {fid_values[-2]:.1f}, {fid_values[-1]:.1f}\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'Slides/FID_{eval_type}_dim_{dim}_scaled.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "    rects1 = ax.bar(x - width/2, fid_values[::2], width, label='Style 0', color='yellowgreen')\n",
    "    rects2 = ax.bar(x + width/2, fid_values[1::2], width, label='Style 1', color='saddlebrown')\n",
    "\n",
    "\n",
    "    if dim == 64: \n",
    "        conf = \"first max pooling features\"\n",
    "    if dim == 192: \n",
    "        conf = \"second max pooling features\"\n",
    "    if dim == 768: \n",
    "        conf = \"pre-aux classifier features\"\n",
    "    if dim == 2048:\n",
    "        conf = \"final average pooling features\"\n",
    "\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('FID Scores')\n",
    "    ax.set_title(f\"FID Score per Model and style comparing predictions and target datasets(lower is better)\\nfeature dim {dim}\\n {conf}\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f'Slides/FID_{eval_type}_dim_{dim}.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a6a36-a38b-4ab3-95ca-f8314f87a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "FID_score(names,experiments,real_style_0,real_style_1, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c99942d-e401-4f86-afbf-15c0a46cb292",
   "metadata": {},
   "outputs": [],
   "source": [
    "FID_score(names,experiments,real_style_0,real_style_1, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf2fd1-3be3-422c-a008-9de169c271e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FID_score(names,experiments,real_style_0,real_style_1, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d4373f-d610-4648-8cdf-fe5721a897b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FID_score(names,experiments,real_style_0,real_style_1, 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5af1c2-651a-4fba-bb09-3f173496ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FID_score(names,experiments,real_style_0,real_style_1, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c460de3-47db-402b-9f62-adaacab61e14",
   "metadata": {},
   "source": [
    "# Ploting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc89869-6bf6-476b-bb3e-c6cc9487b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Existing functions\n",
    "def do_canny_single(img, label, img_type):\n",
    "    if img_type == 'real':\n",
    "        img_gray = rgb2gray(img)\n",
    "        if label == 1:\n",
    "            # brown\n",
    "            img_gray[img_gray <= 0.5] = 0\n",
    "            img_gray[img_gray > 0.5] = 1\n",
    "        else:\n",
    "            # grey\n",
    "            img_gray = feature.canny(img_gray, sigma=6, low_threshold=0.1)\n",
    "\n",
    "        edges = img_gray  # pointer magic\n",
    "    else:\n",
    "        img_gray = np.squeeze(seg_sim(img))\n",
    "        edges = feature.canny(img_gray, sigma=3, low_threshold=0.2)\n",
    "    return edges\n",
    "def seg_sim(image):\n",
    "    aux2 = np.zeros((256, 256, 1), dtype=np.uint8)\n",
    "    aux2[np.where((image[:256, :, 1] >= 98) & (image[:256, :, 1] <= 112))] = [255]\n",
    "    aux2[np.where(image[:256, :, 1] == 107)] = [255]\n",
    "    aux2[np.where(image[:256, :, 1] == 102)] = [255]\n",
    "    aux2[np.where(image[:256, :, 1] == 111)] = [255]\n",
    "\n",
    "    return aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f3e40-2ed1-41ad-80fd-7a5217ba8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAI_edges = np.array([do_canny_single(img, None, \"OpenAI\") for img in openAI_data]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8c2e1-7c8e-4eaf-abe6-3a725d4530c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_type = [\"OpenAI\"]+[\"real\"]*14\n",
    "style_class = [None]+[0,1]*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88271319-4776-4e7a-9c05-95752e0155a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0846bdf-d373-45a1-8cb4-22d817933ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_edges = [np.array([do_canny_single(img, style, typ) for img in gan_data]).astype(float) for (gan_data, style, typ) in zip(experiments,style_class, img_type)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6317c6e-2828-41f6-bd3c-191d6e919ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_data_0_edges = np.array([do_canny_single(img, 0, \"real\") for img in gan_data_0]).astype(float)\n",
    "gan_data_1_edges = np.array([do_canny_single(img, 1, \"real\") for img in gan_data_1]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d28bb50-9ebd-482a-87f0-9458500fdfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_losses(YH, y=OpenAI_edges):\n",
    "    return [np.mean(YH==y), MSE(YH, y), BCE(YH, y), ssim(YH,y), psnr(y,YH), cos_sim(y, YH).mean()]\n",
    "\n",
    "def MSE(YH, Y):\n",
    "    loss = torch.nn.MSELoss()\n",
    "    return loss(torch.from_numpy(Y), torch.from_numpy(YH)).numpy() \n",
    "\n",
    "\n",
    "def BCE(YH, Y):\n",
    "    loss = torch.nn.BCELoss()\n",
    "    return loss(torch.from_numpy(Y), torch.from_numpy(YH)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6929e41f-e371-4172-8f18-0e390544acdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def histo_single_grayscale(image, title, ax):\n",
    "    img = [image]\n",
    "    img_gray = np.array([cv2.cvtColor(im, cv2.COLOR_RGB2GRAY) for im in img])\n",
    "    hist = cv2.calcHist(img_gray, [0], None, [256], [0, 256])\n",
    "    ax.cla()\n",
    "    ax.set_title(f\"Grayscale Histogram {title}\")\n",
    "    ax.set_xlabel(\"Bins\")\n",
    "    ax.set_ylabel(\"# of Pixels\")\n",
    "    ax.plot(hist)\n",
    "    ax.set_xlim([0, 256])\n",
    "    return ax\n",
    "\n",
    "\n",
    "def histo_single(image, title, ax):\n",
    "    img = [image]\n",
    "    colors = (\"r\", \"g\", \"b\")\n",
    "    ax.cla()\n",
    "    ax.set_title(f\"'Flattened' Color Histogram {title}\")\n",
    "    ax.set_xlabel(\"Bins\")\n",
    "    ax.set_ylabel(\"# of Pixels\")\n",
    "    for channel in range(3):\n",
    "        hist = cv2.calcHist(img, [channel], None, [256], [0, 256])\n",
    "        ax.plot(hist, color=colors[channel])\n",
    "        ax.set_xlim([0, 256])\n",
    "    return ax\n",
    "\n",
    "\n",
    "def real_vs_gan_histo(real_data, gan_data, style, save=False):\n",
    "    fig, ax = plt.subplots(2, 5, figsize=(30, 10))\n",
    "    fig.patch.set_alpha(1.)\n",
    "\n",
    "    n = 0\n",
    "    fig.suptitle(f\"Histogram comparison for style {style}, frame {n}\")\n",
    "    ax[0, 0].imshow(real_data[n])\n",
    "    ax[0, 0].set_title('Input real image sample')\n",
    "    ax[0, 0].set_axis_off()\n",
    "\n",
    "    ax[0, 1] = histo_single_grayscale(real_data[n], f\"single image Real\", ax[0, 1])\n",
    "    ax[0, 2] = histo_single_grayscale(real_data.reshape(real_data.shape[0] * real_data.shape[1], real_data.shape[2], real_data.shape[3]), f\"mean Real\", ax[0, 2])\n",
    "    ax[0, 3] = histo_single(real_data[n], f\"single image Real\", ax[0, 3])\n",
    "    ax[0, 4] = histo_single(real_data.reshape(real_data.shape[0] * real_data.shape[1], real_data.shape[2], real_data.shape[3]), f\"mean Real\", ax[0, 4])\n",
    "\n",
    "    ax[1, 0].imshow(gan_data[n])\n",
    "    ax[1, 0].set_title('Generated image sample')\n",
    "    ax[1, 0].set_axis_off()\n",
    "\n",
    "    ax[1, 1] = histo_single_grayscale(gan_data[n], f\"single image Generated\", ax[1, 1])\n",
    "    ax[1, 2] = histo_single_grayscale(gan_data.reshape(gan_data.shape[0] * gan_data.shape[1], gan_data.shape[2], gan_data.shape[3]), f\"mean Generated\", ax[1, 2])\n",
    "    ax[1, 3] = histo_single(gan_data[n], f\"single image Generated\", ax[1, 3])\n",
    "    ax[1, 4] = histo_single(gan_data.reshape(gan_data.shape[0] * gan_data.shape[1], gan_data.shape[2], gan_data.shape[3]), f\"mean Generated\", ax[1, 4])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # plt.savefig(f\"Slides/histo_style_{style}.png\" , bbox_inches='tight')\n",
    "    def update(n):\n",
    "        fig.suptitle(f\"Histogram comparison for style {style}, frame {n}\")\n",
    "        ax[0, 0].imshow(real_data[n])\n",
    "        ax[0, 0].set_title('Input real image sample')\n",
    "        ax[0, 0].set_axis_off()\n",
    "\n",
    "        ax[0, 1] = histo_single_grayscale(real_data[n], f\"single image Real\", ax[0, 1])\n",
    "        ax[0, 3] = histo_single(real_data[n], f\"single image Real\", ax[0, 3])\n",
    "\n",
    "        ax[1, 0].imshow(gan_data[n])\n",
    "        ax[1, 0].set_title('Generated image sample')\n",
    "        ax[1, 0].set_axis_off()\n",
    "\n",
    "        ax[1, 1] = histo_single_grayscale(gan_data[n], f\"single image Generated\", ax[1, 1])\n",
    "        ax[1, 3] = histo_single(gan_data[n], f\"single image Generated\", ax[1, 3])\n",
    "\n",
    "    anim = FuncAnimation(fig, update, frames=frames, interval=1000, save_count=sys.maxsize)\n",
    "    if save:\n",
    "        anim.save(f'Slides/histo_style_{style}.gif', dpi=150, writer='imagemagick')\n",
    "        print(f'Slides/histo_style_{style}.gif done')\n",
    "\n",
    "    plt.show()\n",
    "    return anim\n",
    "\n",
    "def create_subtitle(fig: plt.Figure, grid: SubplotSpec, title: str):\n",
    "    \"Sign sets of subplots with title\"\n",
    "    row = fig.add_subplot(grid)\n",
    "    # the '\\n' is important\n",
    "    row.set_title(f'{title}\\n')\n",
    "    # hide subplot\n",
    "    row.set_frame_on(False)\n",
    "    row.axis('off')\n",
    "\n",
    "def curve_detection(openAI_data, real_style_0, real_style_1, save=False):\n",
    "    def h_trasn_simple(image, label, number, img_type, row):\n",
    "        # Classic straight-line Hough transform\n",
    "\n",
    "        edge = do_canny_single(image, label, img_type)\n",
    "\n",
    "        # Generating figure 1\n",
    "\n",
    "        ax[row, 0].imshow(image, cmap=cm.gray)\n",
    "        ax[row, 0].set_title('Input image')\n",
    "        ax[row, 0].set_axis_off()\n",
    "\n",
    "        ax[row, 1].imshow(edge, cmap=cm.gray)\n",
    "        ax[row, 1].set_title('Canny edge detection')\n",
    "        ax[row, 1].set_axis_off()\n",
    "\n",
    "        if img_type == \"real\":\n",
    "            closed = closing(edge, disk(20))\n",
    "\n",
    "            wt = white_tophat(closed, disk(1))\n",
    "        else:\n",
    "            wt = edge\n",
    "\n",
    "        r = dilation(wt, disk(2))\n",
    "        r = np.pad(r, 2)\n",
    "        contours = measure.find_contours(r, 0.8)\n",
    "\n",
    "        myline = np.linspace(0, 256, 100)\n",
    "\n",
    "        ax[row, 2].cla()\n",
    "        ax[row, 2].imshow(r, cmap=cm.gray)\n",
    "        if img_type == \"real\":\n",
    "            ax[row, 2].set_title('Processed (closing + white_tophat + dilation + padding + contours)')\n",
    "        else:\n",
    "            ax[row, 2].set_title('Processed (dilation + padding + contours)')\n",
    "        ax[row, 2].set_axis_off()\n",
    "\n",
    "        for contour in contours:\n",
    "            ax[row, 2].plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "\n",
    "        ax[row, 3].cla()\n",
    "        ax[row, 3].imshow(np.zeros(edge.shape), cmap=cm.gray)\n",
    "        ax[row, 3].set_title('Fitted curve and points')\n",
    "        ax[row, 3].set_axis_off()\n",
    "\n",
    "        road_type = \"Undefined\"\n",
    "\n",
    "        defined = True\n",
    "\n",
    "        if len(contours) != 0:\n",
    "            contours = contours[np.argmax([c.shape[0] for c in contours])]\n",
    "\n",
    "            x = np.vstack(contours)[:, 0]\n",
    "            y = np.vstack(contours)[:, 1]\n",
    "\n",
    "            ax[row, 3].scatter(y, x)\n",
    "\n",
    "            mymodel = np.poly1d(np.polyfit(x, y, 2))\n",
    "            line = mymodel(myline)\n",
    "\n",
    "            if mymodel(256) > 300 or mymodel(256) < -50:\n",
    "                defined = False\n",
    "\n",
    "            ax[row, 3].plot(line, myline, \"--r\")\n",
    "        else:\n",
    "            defined = False\n",
    "            road_type = \"No road\"\n",
    "        ax[row, 3].set_ylim((edge.shape[0], 0))\n",
    "        ax[row, 3].set_xlim((0, edge.shape[1]))\n",
    "\n",
    "        bottom = np.sum(edge[-20:, :])\n",
    "        if bottom > 10 and defined:\n",
    "            d2 = np.polyder(mymodel, m=2)\n",
    "            d2 = d2(0) * 1000\n",
    "            if d2 < -1:\n",
    "                road_type = \"left curve\"\n",
    "            elif d2 > 1:\n",
    "                road_type = \"right curve\"\n",
    "            else:\n",
    "                road_type = \"Straight road\"\n",
    "\n",
    "            road_type = f\"{road_type}\\nd2: {d2}\"\n",
    "\n",
    "        create_subtitle(fig, grid[row, ::], f\"{road_type}\")\n",
    "\n",
    "    n = 0\n",
    "    fig, ax = plt.subplots(3, 4, figsize=(20, 10))\n",
    "    fig.patch.set_alpha(1.)\n",
    "\n",
    "    grid = plt.GridSpec(3, 4)\n",
    "\n",
    "    h_trasn_simple(openAI_data[n], None, n, \"OpenAI\", 0)\n",
    "\n",
    "    h_trasn_simple(real_style_0[n], 0, n, \"real\", 1)\n",
    "\n",
    "    h_trasn_simple(real_style_1[n], 1, n, \"real\", 2)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    def update(n):\n",
    "        h_trasn_simple(openAI_data[n], None, n, \"OpenAI\", 0)\n",
    "\n",
    "        h_trasn_simple(real_style_0[n], 0, n, \"real\", 1)\n",
    "\n",
    "        h_trasn_simple(real_style_1[n], 1, n, \"real\", 2)\n",
    "\n",
    "    anim = FuncAnimation(fig, update, frames=frames, interval=1000, save_count=sys.maxsize)\n",
    "    if save:\n",
    "        anim.save(f'Slides/curves.gif', dpi=150, writer='imagemagick')\n",
    "        print(f'Slides/curves.gif done')\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ed631-379f-4c4e-bf5d-95286e66b0ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def edge_comp_graphs(experiments, OpenAI_edges, gan_data_0_edges, gan_data_1_edges, save=False):\n",
    "    openAI_data, gan_data_0, gan_data_1 = experiments\n",
    "    n = 0\n",
    "    X = range(OpenAI_edges.shape[0])\n",
    "    fig, ax = plt.subplots(3, 4, figsize=(20, 10))\n",
    "    fig.patch.set_alpha(1.)\n",
    "\n",
    "    losses_0 = np.array([get_losses(y, x) for (x,y) in  zip(gan_data_0_edges,OpenAI_edges)])\n",
    "    losses_1 = np.array([get_losses(y, x) for (x,y) in  zip(gan_data_1_edges,OpenAI_edges)])\n",
    "    losses_n = ['Accuracy', 'MSE', 'BCE', 'SSIM', 'PSNR', 'Cosine similarity']\n",
    "    \n",
    "    \n",
    "    def update(n):\n",
    "        fig.suptitle(f\"Structure comparison, frame {n}\")\n",
    "        ax[0, 0].imshow(openAI_data[n])\n",
    "        ax[0, 0].set_title('Input OpenAI image sample')\n",
    "        ax[0, 0].set_axis_off()\n",
    "\n",
    "        ax[1, 0].imshow(gan_data_0[n])\n",
    "        ax[1, 0].set_title('Generated Style 0')\n",
    "        ax[1, 0].set_axis_off()\n",
    "\n",
    "        ax[2, 0].imshow(gan_data_1[n])\n",
    "        ax[2, 0].set_title('Generated Style 1')\n",
    "        ax[2, 0].set_axis_off()\n",
    "\n",
    "        ax[0, 1].imshow(do_canny_single(openAI_data[n], None, \"OpenAI\"), cmap=cm.gray)\n",
    "        ax[0, 1].set_title('Input OpenAI image sample')\n",
    "        ax[0, 1].set_axis_off()\n",
    "\n",
    "        ax[1, 1].imshow(do_canny_single(gan_data_0[n], 0, \"real\"), cmap=cm.gray)\n",
    "        ax[1, 1].set_title('Generated Style 0')\n",
    "        ax[1, 1].set_axis_off()\n",
    "\n",
    "        ax[2, 1].imshow(do_canny_single(gan_data_1[n], 1, \"real\"), cmap=cm.gray)\n",
    "        ax[2, 1].set_title('Generated Style 1')\n",
    "        ax[2, 1].set_axis_off()\n",
    "        \n",
    "        \n",
    "        l = 0 #loss\n",
    "        for l in range(3):\n",
    "            ax[l, 2].cla()\n",
    "            ax[l, 2].set_title(losses_n[l])\n",
    "            ax[l, 2].scatter(n, losses_0[n,l], color='g')\n",
    "            ax[l, 2].scatter(n, losses_1[n,l], color='brown')\n",
    "            ax[l, 2].plot(X, losses_0[:,l], color='g')\n",
    "            ax[l, 2].plot(X, losses_1[:,l], color='brown')\n",
    "            ax[l, 2].bar(-5, losses_0[:,l].mean(), color='g', label=\"Style 0\")\n",
    "            ax[l, 2].bar(-3, losses_1[:,l].mean(), color='brown', label=\"Style 1\")\n",
    "            ax[l, 2].set_ylim(np.min([losses_0[:,l],losses_1[:,l]])* 0.99, np.max([losses_0[:,l],losses_1[:,l]])*1.01)\n",
    "            ax[l, 2].set_xlabel(\"Frame\")\n",
    "            ax[l, 2].set_ylabel(losses_n[l])\n",
    "            ax[l ,2].legend()\n",
    "            \n",
    "        for l in range(3,6):\n",
    "            ax[l-3, 3].cla()\n",
    "            ax[l-3, 3].set_title(losses_n[l])\n",
    "            ax[l-3, 3].scatter(n, losses_0[n,l], color='g')\n",
    "            ax[l-3, 3].scatter(n, losses_1[n,l], color='brown')\n",
    "            ax[l-3, 3].plot(X, losses_0[:,l], color='g')\n",
    "            ax[l-3, 3].plot(X, losses_1[:,l], color='brown')\n",
    "            ax[l-3, 3].bar(-5, losses_0[:,l].mean(), color='g', label=\"Style 0\")\n",
    "            ax[l-3, 3].bar(-3, losses_1[:,l].mean(), color='brown', label=\"Style 1\")\n",
    "            ax[l-3, 3].set_ylim(np.min([losses_0[:,l],losses_1[:,l]])* 0.99, np.max([losses_0[:,l],losses_1[:,l]])*1.01)\n",
    "            ax[l-3, 3].set_xlabel(\"Frame\")\n",
    "            ax[l-3, 3].set_ylabel(losses_n[l])\n",
    "            ax[l-3, 3].legend()\n",
    "\n",
    "        \n",
    "        plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        steps = 5\n",
    "    else:\n",
    "        steps=1\n",
    "    anim = FuncAnimation(fig, update, frames=np.arange(0,OpenAI_edges.shape[0], steps), interval=500, save_count=sys.maxsize)\n",
    "    if save:\n",
    "        anim.save('Slides/edges_complete.gif', dpi=150, writer='imagemagick')\n",
    "        print(f'Slides/edges_complete.gif done')\n",
    "\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d08b20a-6332-4412-a21f-314b68785f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def edge_comp_box_plots(experiments, OpenAI_edges, gan_data_0_edges, gan_data_1_edges, save=False):\n",
    "    openAI_data, gan_data_0, gan_data_1 = experiments\n",
    "    n = 0\n",
    "    X = range(OpenAI_edges.shape[0])\n",
    "    fig, ax = plt.subplots(3, 4, figsize=(20, 10))\n",
    "    fig.patch.set_alpha(1.)\n",
    "\n",
    "    \n",
    "    losses_0 = np.array([get_losses(y, x) for (x,y) in  zip(gan_data_0_edges,OpenAI_edges)])\n",
    "    losses_1 = np.array([get_losses(y, x) for (x,y) in  zip(gan_data_1_edges,OpenAI_edges)])\n",
    "    losses_n = [r\"Accuracy $\\uparrow$\", r\"MSE $\\downarrow$\", r\"BCE $\\downarrow$\", r\"SSIM $\\uparrow$\", r\"PSNR $\\uparrow$\", r\"Cosine similarity\"]\n",
    "\n",
    "    def update(n):\n",
    "        fig.suptitle(f\"Structure comparison, frame {n}\")\n",
    "        ax[0, 0].imshow(openAI_data[n])\n",
    "        ax[0, 0].set_title('Input OpenAI image sample')\n",
    "        ax[0, 0].set_axis_off()\n",
    "\n",
    "        ax[1, 0].imshow(gan_data_0[n])\n",
    "        ax[1, 0].set_title('Generated Style 0')\n",
    "        ax[1, 0].set_axis_off()\n",
    "\n",
    "        ax[2, 0].imshow(gan_data_1[n])\n",
    "        ax[2, 0].set_title('Generated Style 1')\n",
    "        ax[2, 0].set_axis_off()\n",
    "\n",
    "        ax[0, 1].imshow(do_canny_single(openAI_data[n], None, \"OpenAI\"), cmap=cm.gray)\n",
    "        ax[0, 1].set_title('Input OpenAI image sample')\n",
    "        ax[0, 1].set_axis_off()\n",
    "\n",
    "        ax[1, 1].imshow(do_canny_single(gan_data_0[n], 0, \"real\"), cmap=cm.gray)\n",
    "        ax[1, 1].set_title('Generated Style 0')\n",
    "        ax[1, 1].set_axis_off()\n",
    "\n",
    "        ax[2, 1].imshow(do_canny_single(gan_data_1[n], 1, \"real\"), cmap=cm.gray)\n",
    "        ax[2, 1].set_title('Generated Style 1')\n",
    "        ax[2, 1].set_axis_off()\n",
    "        \n",
    "        \n",
    "        l = 0 #loss\n",
    "        for c in [2,3]:\n",
    "            for r in range(3):\n",
    "                ax[r, c].cla()\n",
    "                ax[r, c].set_title(losses_n[l])\n",
    "                ax[r, c].scatter([0,1], [losses_0[n,l],losses_1[n,l]], color=['g','brown'])\n",
    "                ax[r, c].boxplot([losses_0[:,l], losses_1[:,l]], positions = [0,1])\n",
    "                ax[r, c].set_xticks([0, 1])\n",
    "                ax[r, c].set_xticklabels([\"style 0\", \"style 1\"])\n",
    "                ax[r, c].set_ylabel(losses_n[l])\n",
    "                l+=1\n",
    "\n",
    "        \n",
    "        plt.tight_layout()\n",
    "   \n",
    "\n",
    "    if save:\n",
    "        steps = 5\n",
    "    else:\n",
    "        steps=1\n",
    "        \n",
    "    anim = FuncAnimation(fig, update, frames=np.arange(0,OpenAI_edges.shape[0], steps), interval=500, save_count=sys.maxsize)    \n",
    "    \n",
    "    if save:\n",
    "        anim.save('Slides/edges_complete_boxplot.gif', dpi=150, writer='imagemagick')\n",
    "        print(f'Slides/edges_complete_boxplot.gif done')\n",
    "        \n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c6ad60-5cd6-45bc-934f-022455b22deb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def edge_only_box_plots(OpenAI_edges,edges,edge_names,eval_type,save_steps=10, save=False):\n",
    "    n = 0\n",
    "    X = range(OpenAI_edges.shape[0])\n",
    "    fig, ax = plt.subplots(3, 5, figsize=(25, 10))\n",
    "    fig.patch.set_alpha(1.)\n",
    "    \n",
    "    losses = np.array([np.array([get_losses(y, x) for (x,y) in zip(edge,OpenAI_edges)]) for edge in edges])\n",
    "    losses_n = [r\"Accuracy $\\uparrow$\", r\"MSE $\\downarrow$\", r\"BCE $\\downarrow$\", r\"SSIM $\\uparrow$\", r\"PSNR $\\uparrow$\", r\"Cosine similarity\"]\n",
    "    local_names=['net A_0', 'net A_1', 'net B_0','net B_1','net C_0','net C_1']\n",
    "    \n",
    "    fig.suptitle(f\"Structure comparison, frame {n}\")\n",
    "    ax[0, 0].imshow(openAI_data[n])\n",
    "    ax[0, 0].set_title('Input OpenAI image sample')\n",
    "    ax[0, 0].set_axis_off()\n",
    "\n",
    "    ax[0, 1].imshow(do_canny_single(openAI_data[n], None, \"OpenAI\"), cmap=cm.gray)\n",
    "    ax[0, 1].set_title('Input OpenAI image sample')\n",
    "    ax[0, 1].set_axis_off()\n",
    "\n",
    "\n",
    "    ax[0, 2].set_axis_off()\n",
    "\n",
    "\n",
    "    ax[1, 0].imshow(edges[0][n].astype(bool), cmap=cm.gray)\n",
    "    ax[1, 0].set_title(f'Generated {edge_names[0]},\\n {local_names[0]}')\n",
    "    ax[1, 0].set_axis_off()\n",
    "\n",
    "    ax[2, 0].imshow(edges[1][n].astype(bool), cmap=cm.gray)\n",
    "    ax[2, 0].set_title(f'Generated {edge_names[1]},\\n {local_names[1]}')\n",
    "    ax[2, 0].set_axis_off()\n",
    "\n",
    "    ax[1, 1].imshow(edges[2][n].astype(bool), cmap=cm.gray)\n",
    "    ax[1, 1].set_title(f'Generated {edge_names[2]},\\n {local_names[2]}')\n",
    "    ax[1, 1].set_axis_off()\n",
    "\n",
    "    ax[2, 1].imshow(edges[3][n].astype(bool), cmap=cm.gray)\n",
    "    ax[2, 1].set_title(f'Generated {edge_names[3]},\\n {local_names[3]}')\n",
    "    ax[2, 1].set_axis_off()\n",
    "\n",
    "    ax[1, 2].imshow(edges[4][n].astype(bool), cmap=cm.gray)\n",
    "    ax[1, 2].set_title(f'Generated {edge_names[4]},\\n {local_names[4]}')\n",
    "    ax[1, 2].set_axis_off()\n",
    "\n",
    "    ax[2, 2].imshow(edges[5][n].astype(bool), cmap=cm.gray)\n",
    "    ax[2, 2].set_title(f'Generated {edge_names[5]},\\n {local_names[5]}')\n",
    "    ax[2, 2].set_axis_off()\n",
    "        \n",
    "\n",
    "        \n",
    "    l = 0 #loss\n",
    "    for c in [3,4]:\n",
    "        for r in range(3):\n",
    "            ax[r, c].cla()\n",
    "            ax[r, c].set_title(losses_n[l])\n",
    "            ax[r, c].scatter(range(losses.shape[0]), [loss[n,l] for loss in losses], color=['g','brown']*(losses.shape[0]//2))\n",
    "            ax[r, c].boxplot([loss[:,l] for loss in losses], positions = range(losses.shape[0]))\n",
    "            ax[r, c].set_xticks(range(losses.shape[0]))\n",
    "            ax[r, c].set_xticklabels(local_names)\n",
    "            ax[r, c].set_ylabel(losses_n[l])\n",
    "            l+=1\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    def update(n):\n",
    "        fig.suptitle(f\"Structure comparison, frame {n}\")\n",
    "        ax[0, 0].imshow(openAI_data[n])\n",
    "        ax[0, 0].set_title('Input OpenAI image sample')\n",
    "        ax[0, 0].set_axis_off()\n",
    "\n",
    "        ax[0, 1].imshow(do_canny_single(openAI_data[n], None, \"OpenAI\"), cmap=cm.gray)\n",
    "        ax[0, 1].set_title('Input OpenAI image sample')\n",
    "        ax[0, 1].set_axis_off()\n",
    "        \n",
    "\n",
    "        ax[0, 2].set_axis_off()\n",
    "\n",
    "        \n",
    "        ax[1, 0].imshow(edges[0][n].astype(bool), cmap=cm.gray)\n",
    "        ax[1, 0].set_title(f'Generated {edge_names[0]},\\n {local_names[0]}')\n",
    "        ax[1, 0].set_axis_off()\n",
    "\n",
    "        ax[2, 0].imshow(edges[1][n].astype(bool), cmap=cm.gray)\n",
    "        ax[2, 0].set_title(f'Generated {edge_names[1]},\\n {local_names[1]}')\n",
    "        ax[2, 0].set_axis_off()\n",
    "        \n",
    "        ax[1, 1].imshow(edges[2][n].astype(bool), cmap=cm.gray)\n",
    "        ax[1, 1].set_title(f'Generated {edge_names[2]},\\n {local_names[2]}')\n",
    "        ax[1, 1].set_axis_off()\n",
    "\n",
    "        ax[2, 1].imshow(edges[3][n].astype(bool), cmap=cm.gray)\n",
    "        ax[2, 1].set_title(f'Generated {edge_names[3]},\\n {local_names[3]}')\n",
    "        ax[2, 1].set_axis_off()\n",
    "        \n",
    "        ax[1, 2].imshow(edges[4][n].astype(bool), cmap=cm.gray)\n",
    "        ax[1, 2].set_title(f'Generated {edge_names[4]},\\n {local_names[4]}')\n",
    "        ax[1, 2].set_axis_off()\n",
    "\n",
    "        ax[2, 2].imshow(edges[5][n].astype(bool), cmap=cm.gray)\n",
    "        ax[2, 2].set_title(f'Generated {edge_names[5]},\\n {local_names[5]}')\n",
    "        ax[2, 2].set_axis_off()\n",
    "        \n",
    "        \n",
    "        \n",
    "        l = 0 #loss\n",
    "        for c in [3,4]:\n",
    "            for r in range(3):\n",
    "                ax[r, c].cla()\n",
    "                ax[r, c].set_title(losses_n[l])\n",
    "                ax[r, c].scatter(range(losses.shape[0]), [loss[n,l] for loss in losses], color=['g','brown']*(losses.shape[0]//2))\n",
    "                ax[r, c].boxplot([loss[:,l] for loss in losses], positions = range(losses.shape[0]))\n",
    "                ax[r, c].set_xticks(range(losses.shape[0]))\n",
    "                ax[r, c].set_xticklabels(local_names)\n",
    "                ax[r, c].set_ylabel(losses_n[l])\n",
    "                l+=1\n",
    "\n",
    "        \n",
    "        #plt.tight_layout()\n",
    "   \n",
    "\n",
    "    if save:\n",
    "        steps = save_steps\n",
    "    else:\n",
    "        steps=5\n",
    "        \n",
    "    anim = FuncAnimation(fig, update, frames=np.arange(0,OpenAI_edges.shape[0]-1, steps), interval=2000, save_count=sys.maxsize)    \n",
    "    \n",
    "    if save:        \n",
    "        anim.save(f'Slides/edges_only_boxplot_{eval_type}_{save_steps}.gif', dpi=150, writer='imagemagick')\n",
    "        print(f'Slides/edges_only_boxplot_{eval_type}_{save_steps}.gif done')\n",
    "        \n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889cc4f4-ad29-4a4c-a2ba-6f019062a266",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def style_transfer_only(experiments,names,eval_type,save_steps=10, save=False):\n",
    "    OpenAI = experiments[0]\n",
    "    names= names[1:]\n",
    "    experiments = experiments[1:]\n",
    "    n = 0\n",
    "    fig, ax = plt.subplots(3, 7, figsize=(25, 10))\n",
    "    fig.patch.set_alpha(1.)\n",
    "    \n",
    "    local_names=['net A_0', 'net A_1', 'net B_0','net B_1','net C_0','net C_1','net D_0', 'net D_1', 'net E_0','net E_1','net F_0','net F_1','net G_0','net G_1']\n",
    "    long_names=[n[10:-2] for n in names[::2]]\n",
    "    name_conv='\\n'.join([rf\"{long} $\\rightarrow$ {local[:-2]}\" for (long,local) in zip(long_names,local_names[::2])])\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig.suptitle(f\"Style transfer comparison, frame {n} \\n {name_conv} \")\n",
    "    ax[0, 0].imshow(OpenAI[n])\n",
    "    ax[0, 0].set_title('Input OpenAI image sample')\n",
    "    ax[0, 0].set_axis_off()\n",
    "    ax[0, 1].set_axis_off()\n",
    "    ax[0, 2].set_axis_off()\n",
    "    ax[0, 3].set_axis_off()\n",
    "    ax[0, 4].set_axis_off()\n",
    "    ax[0, 5].set_axis_off()\n",
    "    ax[0, 6].set_axis_off()\n",
    "\n",
    "    index =0\n",
    "    for i in range(names.shape[0]//2):\n",
    "\n",
    "\n",
    "        ax[1, i].imshow(experiments[index][n])\n",
    "        ax[1, i].set_title(local_names[index])\n",
    "        ax[1, i].set_axis_off()\n",
    "\n",
    "        ax[2, i].imshow(experiments[index+1][n])\n",
    "        ax[2, i].set_title(local_names[index+1])\n",
    "        ax[2, i].set_axis_off()\n",
    "\n",
    "        index +=2\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    def update(n):\n",
    "        fig.suptitle(f\"Style transfer comparison, frame {n} \\n {name_conv} \")\n",
    "        ax[0, 0].imshow(OpenAI[n])\n",
    "        ax[0, 0].set_title('Input OpenAI image sample')\n",
    "        ax[0, 0].set_axis_off()\n",
    "        ax[0, 1].set_axis_off()\n",
    "        ax[0, 2].set_axis_off()\n",
    "        ax[0, 3].set_axis_off()\n",
    "        ax[0, 4].set_axis_off()\n",
    "        ax[0, 5].set_axis_off()\n",
    "        ax[0, 6].set_axis_off()\n",
    "    \n",
    "        index =0\n",
    "        for i in range(names.shape[0]//2):\n",
    "            \n",
    "            \n",
    "            ax[1, i].imshow(experiments[index][n])\n",
    "            ax[1, i].set_title(local_names[index])\n",
    "            ax[1, i].set_axis_off()\n",
    "            \n",
    "            ax[2, i].imshow(experiments[index+1][n])\n",
    "            ax[2, i].set_title(local_names[index+1])\n",
    "            ax[2, i].set_axis_off()\n",
    "        \n",
    "            index +=2\n",
    "        \n",
    "        #plt.tight_layout()\n",
    "   \n",
    "\n",
    "    if save:\n",
    "        steps = save_steps\n",
    "    else:\n",
    "        steps=5\n",
    "        \n",
    "    anim = FuncAnimation(fig, update, frames=np.arange(0,OpenAI.shape[0]-1, steps), interval=2000, save_count=sys.maxsize)    \n",
    "    \n",
    "    if save:\n",
    "        anim.save(f'Slides/style_transfer_only_{eval_type}_{save_steps}.gif', dpi=150, writer='imagemagick')\n",
    "        print(f'Slides/style_transfer_only_{eval_type}_{save_steps}.gif done')\n",
    "        \n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f720a4f-7716-4330-9b80-2d1d56464fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def canny_only(experiments,names,eval_type,steps, step_skip=5, save=False):\n",
    "    OpenAI = experiments[0]\n",
    "    names= names[1:]\n",
    "    experiments = experiments[1:]\n",
    "    n = 0\n",
    "    fig, ax = plt.subplots(3, 7, figsize=(35, 25))\n",
    "    fig.patch.set_alpha(1.)\n",
    "    \n",
    "    local_names=['net A_0', 'net A_1', 'net B_0','net B_1','net C_0','net C_1','net D_0', 'net D_1', 'net E_0','net E_1','net F_0','net F_1','net G_0','net G_1']\n",
    "    long_names=[n[10:-2] for n in names[::2]]\n",
    "    name_conv='\\n'.join([rf\"{long} $\\rightarrow$ {local[:-2]}\" for (long,local) in zip(long_names,local_names[::2])])\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig.suptitle(f\"Style transfer comparison, frame {n} \")\n",
    "    ax[0, 0].imshow(OpenAI[n].astype(bool), cmap=cm.gray)\n",
    "    ax[0, 0].set_title('Input OpenAI image sample')\n",
    "    ax[0, 0].set_axis_off()\n",
    "    ax[0, 1].set_axis_off()\n",
    "    ax[0, 2].set_axis_off()\n",
    "    ax[0, 3].set_axis_off()\n",
    "    ax[0, 4].set_axis_off()\n",
    "    ax[0, 5].set_axis_off()\n",
    "    ax[0, 6].set_axis_off()\n",
    "\n",
    "    index =0\n",
    "    for i in range(names.shape[0]//2):\n",
    "\n",
    "\n",
    "        ax[1, i].imshow(experiments[index][n].astype(bool), cmap=cm.gray)\n",
    "        ax[1, i].set_title(local_names[index])\n",
    "        ax[1, i].set_axis_off()\n",
    "\n",
    "        ax[2, i].imshow(experiments[index+1][n].astype(bool), cmap=cm.gray)\n",
    "        ax[2, i].set_title(local_names[index+1])\n",
    "        ax[2, i].set_axis_off()\n",
    "\n",
    "        index +=2\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    def update(n):\n",
    "        fig.suptitle(f\"Style transfer comparison, frame {n} \")\n",
    "        ax[0, 0].imshow(OpenAI[n].astype(bool), cmap=cm.gray)\n",
    "        ax[0, 0].set_title('Input OpenAI image sample')\n",
    "        ax[0, 0].set_axis_off()\n",
    "        ax[0, 1].set_axis_off()\n",
    "        ax[0, 2].set_axis_off()\n",
    "        ax[0, 3].set_axis_off()\n",
    "        ax[0, 4].set_axis_off()\n",
    "        ax[0, 5].set_axis_off()\n",
    "        ax[0, 6].set_axis_off()\n",
    "    \n",
    "        index =0\n",
    "        for i in range(names.shape[0]//2):\n",
    "            \n",
    "            \n",
    "            ax[1, i].imshow(experiments[index][n].astype(bool), cmap=cm.gray)\n",
    "            ax[1, i].set_title(local_names[index])\n",
    "            ax[1, i].set_axis_off()\n",
    "            \n",
    "            ax[2, i].imshow(experiments[index+1][n].astype(bool), cmap=cm.gray)\n",
    "            ax[2, i].set_title(local_names[index+1])\n",
    "            ax[2, i].set_axis_off()\n",
    "        \n",
    "            index +=2\n",
    "        \n",
    "        #plt.tight_layout()\n",
    "   \n",
    "\n",
    "    anim = FuncAnimation(fig, update, frames=np.arange(0,steps*step_skip, step_skip), interval=50, save_count=sys.maxsize)    \n",
    "    \n",
    "    if save:\n",
    "        anim.save(f'Slides/canny_only{eval_type}_{steps}.mp4',  writer='imagemagick')\n",
    "        print(f'Slides/canny_only{eval_type}_{steps}.mp4 done')\n",
    "        \n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01a4852-9a88-44c5-b934-62a84cbffbd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def style_transfer_with_car(experiments,names,eval_type,steps,step_skip=5, save=False):\n",
    "    car = np.load(\"car_positions.npz\")\n",
    "\n",
    "    OpenAI = experiments[0]\n",
    "    names= names[1:]\n",
    "    experiments = experiments[1:]\n",
    "    n = 0\n",
    "    fig, ax = plt.subplots(3, 7, figsize=(35, 25))\n",
    "    fig.patch.set_alpha(1.)\n",
    "    \n",
    "    local_names=['net A_0', 'net A_1', 'net B_0','net B_1','net C_0','net C_1','net D_0', 'net D_1', 'net E_0','net E_1','net F_0','net F_1','net G_0','net G_1']\n",
    "    long_names=[n[10:-2] for n in names[::2]]\n",
    "    name_conv='\\n'.join([rf\"{long} $\\rightarrow$ {local[:-2]}\" for (long,local) in zip(long_names,local_names[::2])])\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig.suptitle(f\"Style transfer comparison, frame {n}\")\n",
    "    frame = np.copy(OpenAI[n])\n",
    "    frame[np.where(car['frame'][:, :, 0] == 204)] = [204, 0, 0]\n",
    "    frame[np.where(car['frame'][:256, :, 0] == 0)] = [0, 0, 0]\n",
    "    \n",
    "    ax[0, 0].imshow(frame)\n",
    "    ax[0, 0].set_title('Input OpenAI image sample')\n",
    "    ax[0, 0].set_axis_off()\n",
    "    ax[0, 1].set_axis_off()\n",
    "    ax[0, 2].set_axis_off()\n",
    "    ax[0, 3].set_axis_off()\n",
    "    ax[0, 4].set_axis_off()\n",
    "    ax[0, 5].set_axis_off()\n",
    "    ax[0, 6].set_axis_off()\n",
    "\n",
    "    index =0\n",
    "    for i in range(names.shape[0]//2):\n",
    "\n",
    "        \n",
    "        frame = np.copy(experiments[index][n])\n",
    "        frame[np.where(car['frame'][:, :, 0] == 204)] = [204, 0, 0]\n",
    "        frame[np.where(car['frame'][:256, :, 0] == 0)] = [0, 0, 0]\n",
    "        ax[1, i].imshow(frame)\n",
    "        ax[1, i].set_title(local_names[index])\n",
    "        ax[1, i].set_axis_off()\n",
    "        \n",
    "        frame = np.copy(experiments[index+1][n])\n",
    "        frame[np.where(car['frame'][:, :, 0] == 204)] = [204, 0, 0]\n",
    "        frame[np.where(car['frame'][:256, :, 0] == 0)] = [0, 0, 0]\n",
    "        ax[2, i].imshow(frame)\n",
    "        ax[2, i].set_title(local_names[index+1])\n",
    "        ax[2, i].set_axis_off()\n",
    "\n",
    "        index +=2\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    def update(n):\n",
    "        fig.suptitle(f\"Style transfer comparison, frame {n} \")\n",
    "        frame = np.copy(OpenAI[n])\n",
    "        frame[np.where(car['frame'][:, :, 0] == 204)] = [204, 0, 0]\n",
    "        frame[np.where(car['frame'][:256, :, 0] == 0)] = [0, 0, 0]\n",
    "\n",
    "        ax[0, 0].imshow(frame)\n",
    "        ax[0, 0].set_title('Input OpenAI image sample')\n",
    "        ax[0, 0].set_axis_off()\n",
    "        ax[0, 1].set_axis_off()\n",
    "        ax[0, 2].set_axis_off()\n",
    "        ax[0, 3].set_axis_off()\n",
    "        ax[0, 4].set_axis_off()\n",
    "        ax[0, 5].set_axis_off()\n",
    "        ax[0, 6].set_axis_off()\n",
    "    \n",
    "        index =0\n",
    "        for i in range(names.shape[0]//2):\n",
    "\n",
    "            frame = np.copy(experiments[index][n])\n",
    "            frame[np.where(car['frame'][:, :, 0] == 204)] = [204, 0, 0]\n",
    "            frame[np.where(car['frame'][:256, :, 0] == 0)] = [0, 0, 0]\n",
    "            ax[1, i].imshow(frame)\n",
    "            ax[1, i].set_title(local_names[index])\n",
    "            ax[1, i].set_axis_off()\n",
    "\n",
    "            frame = np.copy(experiments[index+1][n])\n",
    "            frame[np.where(car['frame'][:, :, 0] == 204)] = [204, 0, 0]\n",
    "            frame[np.where(car['frame'][:256, :, 0] == 0)] = [0, 0, 0]\n",
    "            ax[2, i].imshow(frame)\n",
    "            ax[2, i].set_title(local_names[index+1])\n",
    "            ax[2, i].set_axis_off()\n",
    "        \n",
    "            index +=2\n",
    "        \n",
    "        #plt.tight_layout()\n",
    "   \n",
    "\n",
    "\n",
    "        \n",
    "    anim = FuncAnimation(fig, update, frames=np.arange(0,steps*step_skip, step_skip), interval=50, save_count=sys.maxsize)    \n",
    "    \n",
    "    if save:\n",
    "        anim.save(f'Slides/style_transfer_with_car_{eval_type}_{steps}.mp4', writer='imagemagick')\n",
    "        print(f'Slides/style_transfer_with_car_{eval_type}_{steps}.mp4 done')\n",
    "        \n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcadaf85-ae09-42b3-abaf-8c2aaf33bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imagemagick movie\n",
    "style_transfer_car=style_transfer_with_car(experiments,names,eval_type,steps=200, step_skip=5, save=True)\n",
    "#HTML(style_transfer_car.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e3527a-dda2-41e9-adec-fc7928fd5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cany_on=canny_only(generated_edges,names,eval_type,steps=200, step_skip=5, save=True)\n",
    "#HTML(cany_on.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dec4cd-d52c-4ab8-98de-ec52ea631278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f977ef16-20dc-4677-8559-6c0dfe650f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_transfer_only=style_transfer_only(experiments,names,eval_type,save_steps=50, save=True)\n",
    "#HTML(style_transfer_only.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5305c-3706-4aa3-a58b-89d3ac57172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_box=edge_only_box_plots(OpenAI_edges,edges,edge_names,eval_type,save_steps=50, save=True)\n",
    "#HTML(edges_box.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d02766f-50e4-450c-8daf-2ba661cc46b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db117cbc-7ca5-4640-8556-d595d6f8827b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metrics_only(edges,names,eval_type, save=False):\n",
    "\n",
    "    OpenAI = edges[0]\n",
    "    names= names[1:]\n",
    "    experiments = edges[1:]\n",
    "    n = 0\n",
    "    \n",
    "    X = range(OpenAI.shape[0])\n",
    "\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(25, 15))\n",
    "    fig.patch.set_alpha(1.)\n",
    "    \n",
    "    local_names=['net A_0', 'net A_1', 'net B_0','net B_1','net C_0','net C_1','net D_0', 'net D_1', 'net E_0','net E_1','net F_0','net F_1','net G_0','net G_1']\n",
    "    local_names = local_names[::2]+local_names[1::2]\n",
    "\n",
    "    losses = [np.array([get_losses(y, x) for (x,y) in  zip(exp,OpenAI_edges)]) for exp in experiments]\n",
    "    losses_n = [r\"Accuracy $\\uparrow$\", r\"MSE $\\downarrow$\", r\"BCE $\\downarrow$\", r\"SSIM $\\uparrow$\", r\"PSNR $\\uparrow$\", r\"Cosine similarity\"]\n",
    "\n",
    "\n",
    "\n",
    "    fig.suptitle(f\"Structure comparison\")\n",
    "    \n",
    "        \n",
    "    l = 0 #loss\n",
    "    for c in [0,1]:\n",
    "        for r in range(3):\n",
    "            ax[r, c].cla()\n",
    "            ax[r, c].set_title(losses_n[l])\n",
    "            ax[r, c].boxplot([loss[:,l] for loss in losses][::2], positions = range(len(losses)//2))\n",
    "            ax[r, c].boxplot([loss[:,l] for loss in losses][1::2], positions = range(len(losses)//2,len(losses)))\n",
    "            ax[r, c].set_xticks(range(len(losses)))\n",
    "            ax[r, c].set_xticklabels(local_names)\n",
    "            ax[r, c].set_ylabel(losses_n[l])\n",
    "            l+=1\n",
    "\n",
    "    #plt.tight_layout()\n",
    "\n",
    "\n",
    "    if save:\n",
    "        fig.savefig(f'Slides/metrics_only_{eval_type}.png', dpi=300)\n",
    "        print(f'Slides/metrics_only_{eval_type}.mp4 done')\n",
    "    \n",
    "    plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf5937-2b90-4640-8e90-4f550aaceca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_only= metrics_only(generated_edges,names,eval_type, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b64ef-3a8e-4dd1-b4dc-4fddc6afc69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ax[0, 4] = histo_single(real_data.reshape(real_data.shape[0] * real_data.shape[1], real_data.shape[2], real_data.shape[3]), f\"mean Real\", ax[0, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e768c90-b3a7-4f9b-8b4e-5e171b30f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_style_0.reshape(real_style_0.shape[0] * real_style_0.shape[1], real_style_0.shape[2], real_style_0.shape[3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b86621-8a1e-408c-95ac-73688171d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_style_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af310e5-42a4-49bf-9ace-07aac546ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ex.reshape(ex.shape[0] * ex.shape[1], ex.shape[2], ex.shape[3]).shape for ex in experiments[1::2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c03cfaf-fb7f-4550-b9a1-65e4fb3fa0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d802289-2abd-4e18-8449-8448fafb2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo_single_grayscale(image, title, ax):\n",
    "    img = [image]\n",
    "    img_gray = np.array([cv2.cvtColor(im, cv2.COLOR_RGB2GRAY) for im in img])\n",
    "    hist = cv2.calcHist(img_gray, [0], None, [256], [0, 256])\n",
    "    ax.cla()\n",
    "    ax.set_title(f\"Grayscale Histogram {title}\")\n",
    "    ax.set_xlabel(\"Bins\")\n",
    "    ax.set_ylabel(\"# of Pixels\")\n",
    "    ax.plot(hist)\n",
    "    ax.set_xlim([0, 256])\n",
    "    return ax\n",
    "\n",
    "\n",
    "def histo_single(image, title, ax):\n",
    "    img = [image]\n",
    "    colors = (\"r\", \"g\", \"b\")\n",
    "    ax.cla()\n",
    "    ax.set_title(f\"'Flattened' Color Histogram {title}\")\n",
    "    ax.set_xlabel(\"Bins\")\n",
    "    ax.set_ylabel(\"# of Pixels\")\n",
    "    for channel in range(3):\n",
    "        hist = cv2.calcHist(img, [channel], None, [256], [0, 256])\n",
    "        ax.plot(hist, color=colors[channel])\n",
    "        ax.set_xlim([0, 256])\n",
    "    return ax\n",
    "\n",
    "\n",
    "def real_vs_gan_histo(real_data, gan_data, style, save=False):\n",
    "    fig, ax = plt.subplots(2, 5, figsize=(30, 10))\n",
    "    fig.patch.set_alpha(1.)\n",
    "\n",
    "    n = 0\n",
    "    fig.suptitle(f\"Histogram comparison for style {style}, frame {n}\")\n",
    "    ax[0, 0].imshow(real_data[n])\n",
    "    ax[0, 0].set_title('Input real image sample')\n",
    "    ax[0, 0].set_axis_off()\n",
    "\n",
    "    ax[0, 1] = histo_single_grayscale(real_data[n], f\"single image Real\", ax[0, 1])\n",
    "    ax[0, 2] = histo_single_grayscale(real_data.reshape(real_data.shape[0] * real_data.shape[1], real_data.shape[2], real_data.shape[3]), f\"mean Real\", ax[0, 2])\n",
    "    ax[0, 3] = histo_single(real_data[n], f\"single image Real\", ax[0, 3])\n",
    "    ax[0, 4] = histo_single(real_data.reshape(real_data.shape[0] * real_data.shape[1], real_data.shape[2], real_data.shape[3]), f\"mean Real\", ax[0, 4])\n",
    "\n",
    "    ax[1, 0].imshow(gan_data[n])\n",
    "    ax[1, 0].set_title('Generated image sample')\n",
    "    ax[1, 0].set_axis_off()\n",
    "\n",
    "    ax[1, 1] = histo_single_grayscale(gan_data[n], f\"single image Generated\", ax[1, 1])\n",
    "    ax[1, 2] = histo_single_grayscale(gan_data.reshape(gan_data.shape[0] * gan_data.shape[1], gan_data.shape[2], gan_data.shape[3]), f\"mean Generated\", ax[1, 2])\n",
    "    ax[1, 3] = histo_single(gan_data[n], f\"single image Generated\", ax[1, 3])\n",
    "    ax[1, 4] = histo_single(gan_data.reshape(gan_data.shape[0] * gan_data.shape[1], gan_data.shape[2], gan_data.shape[3]), f\"mean Generated\", ax[1, 4])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd2df85-9dea-4558-8327-3dfe0aa4a4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3daadc-82c0-4f8c-99f8-e84bdea45bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo_comp(real_style_0,real_style_1,experiments,names, save=False):\n",
    "\n",
    "    fig, ax = plt.subplots(2, 4, figsize=(25, 10))\n",
    "\n",
    "\n",
    "\n",
    "    img_gray = np.array([cv2.cvtColor(im, cv2.COLOR_RGB2GRAY) for im in [real_style_0.reshape(real_style_0.shape[0] * real_style_0.shape[1], real_style_0.shape[2], real_style_0.shape[3])]])\n",
    "    target_hist = cv2.calcHist(img_gray, [0], None, [256], [0, 256])\n",
    "    ax[0,0].plot(target_hist/(real_style_0.shape[0] * real_style_0.shape[1]), c='b', label='target',linewidth=3.0)\n",
    "\n",
    "    for i in range(1,experiments.shape[0],2):\n",
    "        exp = experiments[i]\n",
    "        img_gray = np.array([cv2.cvtColor(im, cv2.COLOR_RGB2GRAY) for im in [exp.reshape(exp.shape[0] * exp.shape[1], exp.shape[2], exp.shape[3])]])\n",
    "        target_hist = cv2.calcHist(img_gray, [0], None, [256], [0, 256])\n",
    "        ax[0,0].plot(target_hist/(exp.shape[0] * exp.shape[1]), label=names[i][10:])\n",
    "    ax[0,0].legend()\n",
    "    ax[0,0].set_title(\"Gray histogram Style 0 (Normalized over number of image)\")\n",
    "\n",
    "\n",
    "    img_gray = np.array([cv2.cvtColor(im, cv2.COLOR_RGB2GRAY) for im in [real_style_1.reshape(real_style_1.shape[0] * real_style_1.shape[1], real_style_1.shape[2], real_style_1.shape[3])]])\n",
    "    target_hist = cv2.calcHist(img_gray, [0], None, [256], [0, 256])\n",
    "    ax[1,0].plot(target_hist/(real_style_1.shape[0] * real_style_1.shape[1]), c='b', label='target',linewidth=3.0)\n",
    "\n",
    "    for i in range(2,experiments.shape[0],2):\n",
    "        exp = experiments[i]\n",
    "        img_gray = np.array([cv2.cvtColor(im, cv2.COLOR_RGB2GRAY) for im in [exp.reshape(exp.shape[0] * exp.shape[1], exp.shape[2], exp.shape[3])]])\n",
    "        target_hist = cv2.calcHist(img_gray, [0], None, [256], [0, 256], accumulate=True)\n",
    "        ax[1,0].plot(target_hist/(exp.shape[0] * exp.shape[1]), label=names[i][10:])\n",
    "    ax[1,0].legend()\n",
    "    ax[1,0].set_title(\"Gray histogram Style 1 (Normalized over number of image)\")\n",
    "\n",
    "\n",
    "\n",
    "    col=[\"Red\",\"Green\",\"Blue\"]\n",
    "    for channel in range(3):\n",
    "\n",
    "\n",
    "        target_hist = cv2.calcHist([real_style_0.reshape(real_style_0.shape[0] * real_style_0.shape[1], real_style_0.shape[2], real_style_0.shape[3])], [channel], None, [256], [0, 256])\n",
    "        ax[0,channel+1].plot(target_hist/(real_style_0.shape[0] * real_style_0.shape[1]), c='b', label='target',linewidth=3.0)\n",
    "\n",
    "        for i in range(1,experiments.shape[0],2):\n",
    "            exp = experiments[i]\n",
    "            target_hist = cv2.calcHist([exp.reshape(exp.shape[0] * exp.shape[1], exp.shape[2], exp.shape[3])], [channel], None, [256], [0, 256])\n",
    "            ax[0,channel+1].plot(target_hist/(exp.shape[0] * exp.shape[1]), label=names[i][10:])\n",
    "        ax[0,channel+1].legend()\n",
    "        ax[0,channel+1].set_title(f\"{col[channel]} channel histogram Style 0\")\n",
    "\n",
    "\n",
    "\n",
    "    col=[\"Red\",\"Green\",\"Blue\"]\n",
    "    for channel in range(3):\n",
    "\n",
    "\n",
    "        target_hist = cv2.calcHist([real_style_1.reshape(real_style_1.shape[0] * real_style_1.shape[1], real_style_1.shape[2], real_style_1.shape[3])], [channel], None, [256], [0, 256])\n",
    "        ax[1,channel+1].plot(target_hist/(real_style_1.shape[0] * real_style_1.shape[1]), c='b', label='target',linewidth=3.0)\n",
    "\n",
    "        for i in range(2,experiments.shape[0],2):\n",
    "            exp = experiments[i]\n",
    "            target_hist = cv2.calcHist([exp.reshape(exp.shape[0] * exp.shape[1], exp.shape[2], exp.shape[3])], [channel], None, [256], [0, 256])\n",
    "            ax[1,channel+1].plot(target_hist/(exp.shape[0] * exp.shape[1]), label=names[i][10:])\n",
    "        ax[1,channel+1].legend()\n",
    "        ax[1,channel+1].set_title(f\"{col[channel]} channel histogram Style 1\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        fig.savefig(f'Slides/histo_comp_{eval_type}.png', dpi=300)\n",
    "        print(f'Slides/histo_comp_{eval_type}.png done')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3674678-4e43-45f7-b1a4-f99d9d2a154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_comp(real_style_0,real_style_1,experiments,names, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54b9812-d3ce-400a-98ca-3df92b2ee071",
   "metadata": {},
   "source": [
    "# Curvature comparison\n",
    "### Curve comparison with boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b0160d-2eae-4e7c-88e8-e4d7cbe4a6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_box=edge_comp_box_plots(experiments, OpenAI_edges, gan_data_0_edges, gan_data_1_edges)#, save=True)\n",
    "HTML(curve_box.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e886c07-5a52-40c2-a4b2-6824e29f2405",
   "metadata": {},
   "source": [
    "### Curve comparisson with graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd5087-ec9c-4059-aa9f-312d045053f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_graph=edge_comp_graphs(experiments, OpenAI_edges, gan_data_0_edges, gan_data_1_edges)#, save=True)\n",
    "HTML(curve_graph.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20138fa7-859e-4035-9e1a-48ec945895cc",
   "metadata": {},
   "source": [
    "### Contours comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ebd9a-353d-47d7-b6c5-e70e7f936ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_dect=curve_detection(experiments[0], real_style_0, real_style_1)\n",
    "HTML(curve_dect.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e17288a-1743-4bd4-b462-978b49a13c81",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c7f357-0c50-4fa6-bb0f-ced0df6c8ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_0 = real_vs_gan_histo(real_style_0, experiments[1], \"0\")\n",
    "HTML(histo_0.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbebd24-ea61-4625-bd08-6701220bd30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "histo_1 = real_vs_gan_histo(real_style_1, experiments[2], \"1\")\n",
    "HTML(histo_1.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ab638-42f4-4320-89dd-23f498d37eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "car = np.load(\"car_positions.npz\")\n",
    "width = 800\n",
    "height = 800\n",
    "OpenAI = experiments[0]\n",
    "fig, ax = plt.subplots(1, 3, figsize=(35, 25))\n",
    "fig.patch.set_alpha(1.)\n",
    "ns = np.random.randint(experiments[0].shape[0],  size=3)\n",
    "\n",
    "for i,n in enumerate(ns):\n",
    "    frame = np.copy(OpenAI[n])\n",
    "    frame[np.where(car['frame'][:, :, 0] == 204)] = [204, 0, 0]\n",
    "    frame[np.where(car['frame'][:256, :, 0] == 0)] = [0, 0, 0]\n",
    "    \n",
    "    frame = cv2.resize(frame, dsize=(width, height), interpolation=cv2.INTER_AREA)\n",
    "    ax[i].imshow(frame)\n",
    "    ax[i].set_title('Input OpenAI image sample')\n",
    "    ax[i].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(f'Slides/OpenAI_examples_{eval_type}.png', dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be63583-1aaf-4cdb-9738-90bfdfa48d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314fea84-ef8e-43fd-a887-5691997b3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ra"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
